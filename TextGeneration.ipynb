{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "70e844b1",
   "metadata": {},
   "source": [
    "Text Generation with pre-trained GPT Model.\n",
    "=="
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "f89d007a",
   "metadata": {},
   "outputs": [],
   "source": [
    "import torch\n",
    "from data import get_text_data\n",
    "from models import get_model\n",
    "from utils import load_dict\n",
    "from pathlib import Path\n",
    "from evaluate import generate"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "b7b21bab",
   "metadata": {},
   "outputs": [],
   "source": [
    "device = torch.device('cuda')\n",
    "load_root = Path('./model-store/ex01')\n",
    "args = load_dict(load_root / 'arg.pkl')"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "f3546019",
   "metadata": {},
   "source": [
    "#### Load vocab and tokenizer"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "d7d559ab",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/home/minseong/anaconda3/envs/pytorch_2.3/lib/python3.10/site-packages/torchtext/vocab/__init__.py:4: UserWarning: \n",
      "/!\\ IMPORTANT WARNING ABOUT TORCHTEXT STATUS /!\\ \n",
      "Torchtext is deprecated and the last released version will be 0.18 (this one). You can silence this warning by calling the following at the beginnign of your scripts: `import torchtext; torchtext.disable_torchtext_deprecation_warning()`\n",
      "  warnings.warn(torchtext._TORCHTEXT_DEPRECATION_MSG)\n",
      "/home/minseong/anaconda3/envs/pytorch_2.3/lib/python3.10/site-packages/torchtext/utils.py:4: UserWarning: \n",
      "/!\\ IMPORTANT WARNING ABOUT TORCHTEXT STATUS /!\\ \n",
      "Torchtext is deprecated and the last released version will be 0.18 (this one). You can silence this warning by calling the following at the beginnign of your scripts: `import torchtext; torchtext.disable_torchtext_deprecation_warning()`\n",
      "  warnings.warn(torchtext._TORCHTEXT_DEPRECATION_MSG)\n"
     ]
    }
   ],
   "source": [
    "vocab, tokenizer, datasets = get_text_data(args)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "feea2e09",
   "metadata": {},
   "source": [
    "#### Load a model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "583c37a8",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "<All keys matched successfully>"
      ]
     },
     "execution_count": 4,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "model = get_model(args).to(device)\n",
    "ckpt = torch.load(load_root / 'best_val.pt', map_location=device)\n",
    "model.load_state_dict(ckpt['state_dict'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "1ac74622",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Number of trained steps: 361472\n"
     ]
    }
   ],
   "source": [
    "print(\"Number of trained steps:\", ckpt['step'])"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "3470ec13",
   "metadata": {},
   "source": [
    "#### Text generation with a sample sentence."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "8a8d2ce6",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "i have a good plan to clean my house . \" so , lily went to the store and bought a new toy . she was so happy and said , \" thank you , mommy ! i love my new toy . \" her mom smiled and said , \" you 're welcome , lily . i 'm glad you like it . \" <eot>\n"
     ]
    }
   ],
   "source": [
    "x = 'i have a good plan to clean my house. '\n",
    "generated, _ = generate(model, x, vocab, tokenizer, device, args.max_len)\n",
    "print(generated)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "4f827ae6",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "i like running . i like to play with you . you are my best friend . \" <eot>\n"
     ]
    }
   ],
   "source": [
    "x = 'i like running.'\n",
    "generated, _ = generate(model, x, vocab, tokenizer, device, args.max_len)\n",
    "print(generated)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "25b88dae",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "lily went to the store and bought a new toy . she was so happy and could n't wait to play with it . but when she got home , she saw that her toy was missing . she looked everywhere but could n't find it . lily was sad and did n't know what to do . she asked her mom for help , but her mom did n't know how to fix it . lily was very sad and did n't know what to do . she went to her room and cried . her mom came in and asked what was wrong . lily told her about her missing toy . her mom said , \" do n't worry , we can fix it together . \" they worked together and lily was able to find her toy . she was so happy again . she hugged her mom was so happy again . lily was so happy again . she was so glad that she was n't have to be sad . from now . she was n't have to lose her toy . she was n't have to lose it . lily . she was so sad . she was so sad . her mom was so sad . her mom was so sad . her mom was so sad . her mom was so sad . her mom was so sad . she was so sad . her mom was so sad . her mom was so sad . she\n"
     ]
    }
   ],
   "source": [
    "x = 'lily went to the store and bought a new toy.'\n",
    "generated, _ = generate(model, x, vocab, tokenizer, device, args.max_len)\n",
    "print(generated)"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "pytorch_2.3",
   "language": "python",
   "name": "pytorch_2.3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.14"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
